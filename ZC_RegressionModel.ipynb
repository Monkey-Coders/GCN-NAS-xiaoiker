{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StratifiedGroupKFold' from 'sklearn.model_selection' (/home/max_zaim/anaconda3/envs/zaim/lib/python3.9/site-packages/sklearn/model_selection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m PolynomialFeatures\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error, r2_score, mean_absolute_error\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoML\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpipeline\u001b[39;00m \u001b[39mimport\u001b[39;00m Pipeline\n",
      "File \u001b[0;32m~/anaconda3/envs/zaim/lib/python3.9/site-packages/flaml/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoML, logger_formatter\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtune\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msearcher\u001b[39;00m \u001b[39mimport\u001b[39;00m CFO, BlendSearch, FLOW2, BlendSearchTuner, RandomSearch\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39monlineml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautovw\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoVW\n",
      "File \u001b[0;32m~/anaconda3/envs/zaim/lib/python3.9/site-packages/flaml/automl/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoML, size\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m logger_formatter\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstate\u001b[39;00m \u001b[39mimport\u001b[39;00m SearchState, AutoMLState\n",
      "File \u001b[0;32m~/anaconda3/envs/zaim/lib/python3.9/site-packages/flaml/automl/automl.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39m# TODO check to see when we can remove these\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m CLASSIFICATION, TS_FORECAST, Task\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfactory\u001b[39;00m \u001b[39mimport\u001b[39;00m task_factory\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m \u001b[39mimport\u001b[39;00m tune\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlogger\u001b[39;00m \u001b[39mimport\u001b[39;00m logger, logger_formatter\n",
      "File \u001b[0;32m~/anaconda3/envs/zaim/lib/python3.9/site-packages/flaml/automl/task/factory.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgeneric_task\u001b[39;00m \u001b[39mimport\u001b[39;00m GenericTask\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m Task\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtask_factory\u001b[39m(\n\u001b[1;32m     11\u001b[0m     task_name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     12\u001b[0m     X_train: Optional[Union[np\u001b[39m.\u001b[39mndarray, pd\u001b[39m.\u001b[39mDataFrame]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     13\u001b[0m     y_train: Optional[Union[np\u001b[39m.\u001b[39mndarray, pd\u001b[39m.\u001b[39mDataFrame, pd\u001b[39m.\u001b[39mSeries]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Task:\n",
      "File \u001b[0;32m~/anaconda3/envs/zaim/lib/python3.9/site-packages/flaml/automl/task/generic_task.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mimport\u001b[39;00m issparse\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m shuffle\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     train_test_split,\n\u001b[1;32m     12\u001b[0m     RepeatedStratifiedKFold,\n\u001b[1;32m     13\u001b[0m     RepeatedKFold,\n\u001b[1;32m     14\u001b[0m     GroupKFold,\n\u001b[1;32m     15\u001b[0m     TimeSeriesSplit,\n\u001b[1;32m     16\u001b[0m     GroupShuffleSplit,\n\u001b[1;32m     17\u001b[0m     StratifiedGroupKFold,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m TS_TIMESTAMP_COL, concat\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mflaml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mautoml\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mml\u001b[39;00m \u001b[39mimport\u001b[39;00m EstimatorSubclass, default_cv_score_agg_func, get_val_loss\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StratifiedGroupKFold' from 'sklearn.model_selection' (/home/max_zaim/anaconda3/envs/zaim/lib/python3.9/site-packages/sklearn/model_selection/__init__.py)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from flaml import AutoML\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"MAE (Mean absolute error): {mae:.4f}\")\n",
    "    print(f\"MSE (Mean squared error): {mse:.4f}\")\n",
    "    print(f\"RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "\n",
    "def is_valid_entry(entry, features):\n",
    "    for feature in features:\n",
    "        if feature not in entry or entry[feature] is None:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def train_evaluate_flaml(X_train, y_train, X_test, y_test, time_budget):\n",
    "    automl = AutoML()\n",
    "    settings = {\n",
    "        \"time_budget\": time_budget,  # in seconds\n",
    "        \"metric\": 'r2',\n",
    "        \"task\": 'regression',\n",
    "        \"log_file_name\": 'flaml_regression.log'\n",
    "    }\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "    y_pred = automl.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return mae, mse, rmse, r2, automl\n",
    "\n",
    "def log_transform_features(X):\n",
    "    return np.log1p(np.abs(X))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiment/data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Keep only valid data points\n",
    "features = [\n",
    "    \"plain\",\n",
    "    \"params\",\n",
    "    \"flops\",\n",
    "    \"synflow\",\n",
    "    \"snip\",\n",
    "    \"grad_norm\",\n",
    "    \"epe_nas\",\n",
    "    \"grasp\",\n",
    "    \"fisher\",\n",
    "    \"l2_norm\",\n",
    "    \"jacov\",\n",
    "    \"zen\",\n",
    "    \"nwot\",\n",
    "    \"grad_sign\",\n",
    "]\n",
    "valid_data = [entry for entry in data if is_valid_entry(entry, features + [\"val_acc\"])]\n",
    "\n",
    "# Extract the features (zero-cost proxies) and target (validation accuracy)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for entry in valid_data:\n",
    "    feature_values = [entry[feature] for feature in features if feature != \"val_acc\"]\n",
    "    X.append(feature_values)\n",
    "    y.append(entry[\"val_acc\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results():\n",
    "    # Check if supervised_experiments/results.json exists\n",
    "    try:\n",
    "        with open('supervised_experiments/results.json', 'r') as f:\n",
    "            results = json.load(f)\n",
    "            return results\n",
    "    except:\n",
    "        return {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate FLAML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard method with all proxies for 60 seconds\n",
    "\n",
    "Here we use a StandardScaler as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 60,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": 'flaml_regression.log'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results()\n",
    "results_key = \"all_zero_cost_proxies_60_seconds\"\n",
    "\n",
    "# Check if results_key exists in supervised_experiments/results.json\n",
    "if results_key not in results:\n",
    "    results[results_key] = {}\n",
    "\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "    y_pred = automl.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[results_key][\"mae\"] = mae\n",
    "    results[results_key][\"mse\"] = mse\n",
    "    results[results_key][\"rmse\"] = rmse\n",
    "    results[results_key][\"r2\"] = r2\n",
    "\n",
    "    with open('supervised_experiments/results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "else:\n",
    "    print(\"Results already exist for\", results_key)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase time budget to 120 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 120,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": 'flaml_regression.log'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results()\n",
    "results_key = \"all_zero_cost_proxies_120_seconds\"\n",
    "\n",
    "# Check if results_key exists in supervised_experiments/results.json\n",
    "if results_key not in results:\n",
    "    results[results_key] = {}\n",
    "\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "    y_pred = automl.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[results_key][\"mae\"] = mae\n",
    "    results[results_key][\"mse\"] = mse\n",
    "    results[results_key][\"rmse\"] = rmse\n",
    "    results[results_key][\"r2\"] = r2\n",
    "\n",
    "    with open('supervised_experiments/results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "else:\n",
    "    print(\"Results already exist for\", results_key)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time budget of 300s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 300,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": 'flaml_regression.log'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results()\n",
    "results_key = \"all_zero_cost_proxies_300_seconds\"\n",
    "\n",
    "# Check if results_key exists in supervised_experiments/results.json\n",
    "if results_key not in results:\n",
    "    results[results_key] = {}\n",
    "\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "    y_pred = automl.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[results_key][\"mae\"] = mae\n",
    "    results[results_key][\"mse\"] = mse\n",
    "    results[results_key][\"rmse\"] = rmse\n",
    "    results[results_key][\"r2\"] = r2\n",
    "\n",
    "    with open('supervised_experiments/results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "else:\n",
    "    print(\"Results already exist for\", results_key)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use early stopping with high time budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 3000,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": 'flaml_regression.log',\n",
    "    \"early_stop\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_results()\n",
    "results_key = \"all_zero_cost_proxies_with_early_stopping_max_3000_seconds\"\n",
    "\n",
    "# Check if results_key exists in supervised_experiments/results.json\n",
    "if results_key not in results:\n",
    "    results[results_key] = {}\n",
    "\n",
    "    automl.fit(X_train=X_train, y_train=y_train, **settings)\n",
    "\n",
    "    y_pred = automl.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[results_key][\"mae\"] = mae\n",
    "    results[results_key][\"mse\"] = mse\n",
    "    results[results_key][\"rmse\"] = rmse\n",
    "    results[results_key][\"r2\"] = r2\n",
    "\n",
    "    with open('supervised_experiments/results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "else:\n",
    "    print(\"Results already exist for\", results_key)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check how the R2-score is progressing \n",
    "\n",
    "### Is it worth it to have a higher time budget?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the results from the automl.fit() call\n",
    "\n",
    "from flaml.automl.data import get_output_from_log\n",
    "\n",
    "log_file_name = 'flaml_regression.log'\n",
    "search_time_list, best_error_list, error_list, config_list, logged_metric_list, = get_output_from_log(log_file_name, time_budget=3000)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we try with Recursive Feature Elimination with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiment/data.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Keep only valid data points\n",
    "features = [\n",
    "    \"plain\",\n",
    "    \"params\",\n",
    "    \"flops\",\n",
    "    \"synflow\",\n",
    "    \"snip\",\n",
    "    \"grad_norm\",\n",
    "    \"epe_nas\",\n",
    "    \"grasp\",\n",
    "    \"fisher\",\n",
    "    \"l2_norm\",\n",
    "    \"jacov\",\n",
    "    \"zen\",\n",
    "    \"nwot\",\n",
    "    \"grad_sign\",\n",
    "]\n",
    "valid_data = [entry for entry in data if is_valid_entry(entry, features + [\"val_acc\"])]\n",
    "\n",
    "# Extract the features (zero-cost proxies) and target (validation accuracy)\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for entry in valid_data:\n",
    "    feature_values = [entry[feature] for feature in features if feature != \"val_acc\"]\n",
    "    X.append(feature_values)\n",
    "    y.append(entry[\"val_acc\"])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "class FlamlWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, automl):\n",
    "        self.automl = automl\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.automl.fit(X, y, task=\"regression\")\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.automl.predict(X)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return self.automl.score(X, y)\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        model = self.automl.model.estimator\n",
    "        if hasattr(model, \"feature_importances_\"):\n",
    "            return model.feature_importances_\n",
    "        elif hasattr(model, \"coef_\"):\n",
    "            return np.abs(model.coef_)\n",
    "        else:\n",
    "            raise ValueError(\"Model does not have feature_importances_ or coef_ attribute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoML()\n",
    "flaml_wrapper = FlamlWrapper(automl)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rfecv = RFECV(estimator=flaml_wrapper, step=1, cv=cv, scoring=\"r2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfecv.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "\n",
    "selected_features_mask = rfecv.support_\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_features = [feature for feature, selected in zip(features, selected_features_mask) if selected]\n",
    "\n",
    "print(\"Selected features:\", selected_features) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Transform the training and test data to keep only the selected features\n",
    "X_train_selected = rfecv.transform(X_train)\n",
    "X_test_selected = rfecv.transform(X_test)\n",
    "\n",
    "# Train your FLAML model on the transformed training data\n",
    "automl.fit(X_train_selected, y_train, task=\"regression\")\n",
    "\n",
    "# Evaluate the performance on the transformed test data\n",
    "y_pred = automl.predict(X_test_selected)\n",
    "r2 = automl.score(X_test_selected, y_test)\n",
    "print(\"Test R2 score:\", r2) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at ranking instead of pure regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "automl = AutoML()\n",
    "settings = {\n",
    "    \"time_budget\": 60,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": 'flaml_regression.log'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosklearn.regression import AutoSklearnRegressor\n",
    "results = get_results()\n",
    "results_key = \"rank\"\n",
    "\n",
    "# Check if results_key exists in supervised_experiments/results.json\n",
    "if results_key not in results:\n",
    "    # Convert validation accuracy to ranking\n",
    "    y_rank = (-y).argsort().argsort() + 1\n",
    "\n",
    "    # Split the data for ranking\n",
    "    X_train_rank, X_test_rank, y_train_rank, y_test_rank = train_test_split(X, y_rank, test_size=0.2, random_state=42)\n",
    "    # Initialize the AutoML regressor\n",
    "    automl_rank = AutoSklearnRegressor(\n",
    "        time_left_for_this_task=3600,  # Adjust the time limit based on your needs\n",
    "        per_run_time_limit=300,\n",
    "        n_jobs=-1,\n",
    "        metric=mse\n",
    "    )\n",
    "\n",
    "    # Train the AutoML regressor on the ranking dataset\n",
    "    automl_rank.fit(X_train_rank, y_train_rank)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred_rank = automl_rank.predict(X_test_rank)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zaim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
